
val_error before train: 4.115541458129883
optimizer set.
Starting train epoch 1 / 50
loss: 0.8687319159507751
loss: 0.6333791017532349
loss: 0.5328503847122192
loss: 0.6206225156784058
loss: 0.3047413229942322
loss: 0.41709673404693604
loss: 0.40500950813293457
loss: 0.3369714319705963
loss: 0.6016262173652649
loss: 0.37495094537734985
loss: 0.27865076065063477
loss: 0.6114189624786377
loss: 0.22183938324451447
loss: 0.48962751030921936
loss: 0.3034220039844513
loss: 0.3704923093318939
loss: 0.6905862092971802
loss: 0.4240100681781769
loss: 0.3361491858959198
epoch loss: 0.4643250774396093
val_error: 4.18031644821167
optimizer set.
Starting train epoch 2 / 50
loss: 0.46026933193206787
loss: 0.31080910563468933
loss: 0.31360653042793274
loss: 0.18661732971668243
loss: 0.2311304807662964
loss: 0.17780686914920807
loss: 0.26234376430511475
loss: 0.23159167170524597
loss: 0.34983110427856445
loss: 0.18704810738563538
loss: 0.2074337601661682
loss: 0.4320615231990814
loss: 0.26351720094680786
loss: 0.2756619453430176
loss: 0.21667002141475677
loss: 0.21452362835407257
loss: 0.29804855585098267
loss: 0.2586537301540375
loss: 0.16641691327095032
epoch loss: 0.26547587231585856
val_error: 4.468578338623047
optimizer set.
Starting train epoch 3 / 50
loss: 0.2136002779006958
loss: 0.28242528438568115
loss: 0.27818402647972107
loss: 0.23268482089042664
loss: 0.16571740806102753
loss: 0.16124485433101654
loss: 0.21340249478816986
loss: 0.19628334045410156
loss: 0.18813404440879822
loss: 0.18232788145542145
loss: 0.2803204655647278
1loss: 0.19520477950572968
loss: 0.36399316787719727
loss: 0.2743881344795227
loss: 0.19289815425872803
loss: 0.31874147057533264
loss: 0.2601145803928375
loss: 0.19143305718898773
loss: 0.2437499612569809
epoch loss: 0.23341306338184759
val_error: 4.03261137008667
optimizer set.
Starting train epoch 4 / 50
loss: 0.21921567618846893
loss: 0.19694985449314117
loss: 0.2038460224866867
loss: 0.2699509561061859
loss: 0.19613736867904663
loss: 0.16041161119937897
loss: 0.35480085015296936
loss: 0.19401676952838898
loss: 0.14565986394882202
loss: 0.2674807608127594
loss: 0.20486851036548615
loss: 0.15750548243522644
loss: 0.2567864656448364
loss: 0.21046367287635803
loss: 0.2336932271718979
loss: 0.26258376240730286
loss: 0.260391503572464
loss: 0.15906643867492676
loss: 0.21844251453876495
epoch loss: 0.21959322690963745
val_error: 3.7594685554504395
optimizer set.
Starting train epoch 5 / 50
loss: 0.21360215544700623
loss: 0.2694595754146576
loss: 0.17525140941143036
loss: 0.16742761433124542
loss: 0.1732659637928009
loss: 0.2217683345079422
loss: 0.4060172736644745
loss: 0.2026640772819519
loss: 0.2222600281238556
loss: 0.20955012738704681
loss: 0.15006524324417114
loss: 0.19363203644752502
loss: 0.2660202980041504
loss: 0.15489177405834198
loss: 0.18101896345615387
loss: 0.19730015099048615
loss: 0.30416521430015564
loss: 0.17218422889709473
loss: 0.23107799887657166
epoch loss: 0.2164011825072138
val_error: 4.42848539352417
optimizer set.
Starting train epoch 6 / 50
loss: 0.1650313138961792
loss: 0.20746470987796783
loss: 0.15196748077869415
loss: 0.2059784233570099
loss: 0.2124377191066742
loss: 0.23715801537036896
loss: 0.25038769841194153
loss: 0.13464781641960144
loss: 0.13486197590827942
loss: 0.24078026413917542
loss: 0.1533266305923462
loss: 0.23288166522979736
loss: 0.19867976009845734
loss: 0.18403483927249908
loss: 0.23391975462436676
loss: 0.1360764354467392
loss: 0.18778900802135468
loss: 0.14523103833198547
loss: 0.38065966963768005
epoch loss: 0.19964811676426938
val_error: 1.5236620903015137
optimizer set.
Starting train epoch 7 / 50
loss: 0.1715005338191986
loss: 0.21230976283550262
loss: 0.19608759880065918
loss: 0.17135079205036163
loss: 0.15382705628871918
loss: 0.4936019778251648
loss: 0.11233726143836975
loss: 0.16800275444984436
loss: 0.17645297944545746
loss: 0.3410365879535675
loss: 0.19975745677947998
loss: 0.14718306064605713
loss: 0.15735448896884918
loss: 0.2040199339389801
loss: 0.1730622500181198
loss: 0.1696535348892212
loss: 0.20302781462669373
loss: 0.17676779627799988
loss: 0.16751083731651306
epoch loss: 0.19972865675625048
val_error: 0.17106792330741882
optimizer set.
Starting train epoch 8 / 50
loss: 0.0971507802605629
loss: 0.24554461240768433
loss: 0.1936814934015274
loss: 0.17713476717472076
loss: 0.18263912200927734
loss: 0.17136983573436737
loss: 0.1546282023191452
loss: 0.2452438324689865
loss: 0.2858884930610657
loss: 0.14120711386203766
loss: 0.2479141503572464
loss: 0.18312892317771912
loss: 0.17147037386894226
loss: 0.19864600896835327
loss: 0.1677858680486679
loss: 0.24700403213500977
loss: 0.1964927762746811
loss: 0.1523343324661255
loss: 0.16819216310977936
epoch loss: 0.19091878321609998
val_error: 0.14350444078445435
optimizer set.
Starting train epoch 9 / 50
loss: 0.148260235786438
loss: 0.24489496648311615
loss: 0.15992631018161774
loss: 0.17994846403598785
loss: 0.18967260420322418
loss: 0.27775537967681885
loss: 0.1695544272661209
loss: 0.18323679268360138
loss: 0.2412182092666626
loss: 0.16123439371585846
loss: 0.2020452618598938
loss: 0.17021842300891876
loss: 0.16384652256965637
loss: 0.1481296271085739
loss: 0.19647549092769623
loss: 0.2962222397327423
loss: 0.10913822799921036
loss: 0.20821115374565125
loss: 0.29901009798049927
epoch loss: 0.1973157278016994
val_error: 0.15923666954040527
optimizer set.
Starting train epoch 10 / 50
loss: 0.143434077501297
loss: 0.13100863993167877
loss: 0.1862519234418869
loss: 0.138703852891922
loss: 0.1614455282688141
loss: 0.10738278925418854
loss: 0.20339465141296387
loss: 0.19360996782779694
loss: 0.15632589161396027
loss: 0.2319527566432953
loss: 0.14704367518424988
loss: 0.23005826771259308
loss: 0.24245092272758484
loss: 0.12277506291866302
loss: 0.16843003034591675
loss: 0.1475190967321396
loss: 0.2545984983444214
loss: 0.19272206723690033
loss: 0.16060250997543335
epoch loss: 0.17472158999819504
val_error: 0.13231942057609558
optimizer set.
Starting train epoch 11 / 50
loss: 0.1870814710855484
loss: 0.1580888032913208
loss: 0.10883849114179611
loss: 0.24292060732841492
loss: 0.16839778423309326
loss: 0.34930646419525146
loss: 0.20668423175811768
loss: 0.1689465194940567
loss: 0.1318085491657257
loss: 0.1564834713935852
loss: 0.15391336381435394
loss: 0.19904761016368866
loss: 0.13463054597377777
loss: 0.20450860261917114
loss: 0.20982788503170013
loss: 0.0957091823220253
loss: 0.1588142067193985
loss: 0.21337462961673737
loss: 0.14263109862804413
epoch loss: 0.17847439568293721
val_error: 0.13361164927482605
optimizer set.
Starting train epoch 12 / 50
loss: 0.23028595745563507
loss: 0.18111322820186615
loss: 0.19005298614501953
loss: 0.213261678814888
loss: 0.2044074535369873
loss: 0.16910187900066376
loss: 0.2533878982067108
loss: 0.23356856405735016
loss: 0.12458886206150055
loss: 0.14872996509075165
loss: 0.1095457449555397
loss: 0.1727970391511917
loss: 0.1988135725259781
loss: 0.16151225566864014
loss: 0.15602682530879974
loss: 0.12559765577316284
loss: 0.12212367355823517
loss: 0.18388734757900238
loss: 0.10859016329050064
epoch loss: 0.17302067107275912
val_error: 0.15352590382099152
optimizer set.
Starting train epoch 13 / 50
loss: 0.13471293449401855
loss: 0.12105061113834381
loss: 0.26538097858428955
loss: 0.22668606042861938
loss: 0.2538512349128723
loss: 0.1789538711309433
loss: 0.2355627417564392
loss: 0.19182927906513214
loss: 0.12059205770492554
loss: 0.1575678437948227
loss: 0.12885329127311707
loss: 0.16362370550632477
loss: 0.26246023178100586
loss: 0.2298271209001541
loss: 0.17623737454414368
loss: 0.13028135895729065
loss: 0.11912667751312256
loss: 0.13850706815719604
loss: 0.18025434017181396
epoch loss: 0.17975572535866186
val_error: 0.15142704546451569
optimizer set.
Starting train epoch 14 / 50
loss: 0.16064974665641785
loss: 0.14299848675727844
loss: 0.15533870458602905
loss: 0.2475154548883438
loss: 0.16294439136981964
loss: 0.1762821078300476
loss: 0.18109484016895294
loss: 0.13799835741519928
loss: 0.11375026404857635
loss: 0.13151530921459198
loss: 0.1605258733034134
loss: 0.1706598997116089
loss: 0.0983378142118454
loss: 0.18210962414741516
loss: 0.21589888632297516
loss: 0.12449386715888977
loss: 0.2102535218000412
loss: 0.14048215746879578
loss: 0.16264547407627106
epoch loss: 0.16186814637560593
val_error: 0.15208691358566284
optimizer set.
Starting train epoch 15 / 50
loss: 0.1184452474117279
loss: 0.09485791623592377
loss: 0.11912792176008224
loss: 0.1422487497329712
loss: 0.2057618498802185
loss: 0.11578474193811417
loss: 0.1424379050731659
loss: 0.2773633897304535
loss: 0.1466389298439026
loss: 0.10946334898471832
loss: 0.10971235483884811
loss: 0.07453883439302444
loss: 0.12361478805541992
loss: 0.19929714500904083
loss: 0.17354907095432281
loss: 0.1254138946533203
loss: 0.14036625623703003
loss: 0.16005685925483704
loss: 0.12072855234146118
epoch loss: 0.14207409243834646
val_error: 0.13164231181144714
optimizer set.
Starting train epoch 16 / 50
loss: 0.1580774188041687
loss: 0.18241462111473083
loss: 0.12329684942960739
loss: 0.13765114545822144
loss: 0.16181397438049316
loss: 0.11804904043674469
loss: 0.12359613925218582
loss: 0.23735113441944122
loss: 0.14415264129638672
loss: 0.15571922063827515
loss: 0.18220989406108856
loss: 0.20910745859146118
loss: 0.15971066057682037
loss: 0.1009153351187706
loss: 0.07480589300394058
loss: 0.20299169421195984
loss: 0.1279367357492447
loss: 0.16069413721561432
loss: 0.1341710388660431
epoch loss: 0.15235079119079992
val_error: 0.15031090378761292
optimizer set.
Starting train epoch 17 / 50
loss: 0.15223141014575958
loss: 0.13401474058628082
loss: 0.1331501007080078
loss: 0.13172294199466705
loss: 0.1919361799955368
loss: 0.279857337474823
loss: 0.25849246978759766
loss: 0.12863148748874664
loss: 0.11715172231197357
loss: 0.13764582574367523
loss: 0.1657579243183136
loss: 0.19874480366706848
loss: 0.20432202517986298
loss: 0.14099575579166412
loss: 0.1599242240190506
loss: 0.1821831911802292
loss: 0.15585550665855408
loss: 0.14080055058002472
loss: 0.14045242965221405
epoch loss: 0.16599319090968684
val_error: 0.15303093194961548
optimizer set.
Starting train epoch 18 / 50
loss: 0.15616868436336517
loss: 0.24034106731414795
loss: 0.13545335829257965
loss: 0.12432761490345001
loss: 0.11676694452762604
loss: 0.21533943712711334
loss: 0.228465273976326
loss: 0.14552809298038483
loss: 0.15726208686828613
loss: 0.12679730355739594
loss: 0.24845349788665771
loss: 0.14883831143379211
loss: 0.17573215067386627
loss: 0.13774003088474274
loss: 0.12899279594421387
loss: 0.14113390445709229
loss: 0.15801557898521423
loss: 0.19227971136569977
loss: 0.14690770208835602
epoch loss: 0.16444966040159525
val_error: 0.15762397646903992
optimizer set.
Starting train epoch 19 / 50
loss: 0.1199941635131836
loss: 0.19482430815696716
loss: 0.1466621607542038
loss: 0.12286357581615448
loss: 0.1662604957818985
loss: 0.1521049439907074
loss: 0.13389474153518677
loss: 0.08639102429151535
loss: 0.10355169326066971
loss: 0.15333008766174316
loss: 0.1550550013780594
loss: 0.14619779586791992
loss: 0.20387707650661469
loss: 0.18562185764312744
loss: 0.13463684916496277
loss: 0.2817226052284241
loss: 0.16033034026622772
loss: 0.15569663047790527
loss: 0.12718172371387482
epoch loss: 0.15422089868470243
val_error: 0.1613963395357132
optimizer set.
Starting train epoch 20 / 50
loss: 0.08937624096870422
loss: 0.10860627889633179
loss: 0.09716986864805222
loss: 0.12273582816123962
loss: 0.2381017506122589
loss: 0.12357845157384872
loss: 0.19808118045330048
loss: 0.1968982070684433
loss: 0.21529826521873474
loss: 0.20092007517814636
loss: 0.16464771330356598
loss: 0.18762241303920746
loss: 0.13740213215351105
loss: 0.07552666962146759
loss: 0.13712365925312042
loss: 0.1534406691789627
loss: 0.13769802451133728
loss: 0.12126379460096359
loss: 0.1441010683774948
epoch loss: 0.1499785416220364
val_error: 0.1446901559829712
optimizer set.
Starting train epoch 21 / 50
loss: 0.10200810432434082
loss: 0.2788996994495392
loss: 0.13775566220283508
loss: 0.1827184408903122
loss: 0.20652572810649872
loss: 0.20417554676532745
loss: 0.16829584538936615
loss: 0.1942569762468338
loss: 0.17574986815452576
loss: 0.19239453971385956
loss: 0.15732787549495697
loss: 0.15892283618450165
loss: 0.17591221630573273
loss: 0.12379947304725647
loss: 0.20404314994812012
loss: 0.1716984063386917
loss: 0.2822783291339874
loss: 0.15446530282497406
loss: 0.14533238112926483
epoch loss: 0.1798189674553118
val_error: 0.13744626939296722
optimizer set.
Starting train epoch 22 / 50
loss: 0.10562525689601898
loss: 0.16766394674777985
loss: 0.16276131570339203
loss: 0.16561664640903473
loss: 0.12629978358745575
loss: 0.08331839740276337
loss: 0.16682270169258118
loss: 0.1910834014415741
loss: 0.16031019389629364
loss: 0.1755739450454712
loss: 0.10976233333349228
loss: 0.10547617822885513
loss: 0.1370573788881302
loss: 0.11839493364095688
loss: 0.11623059213161469
loss: 0.1337892860174179
loss: 0.17048603296279907
loss: 0.20821985602378845
loss: 0.13368993997573853
epoch loss: 0.14411484842237673
val_error: 0.15407820045948029
optimizer set.
Starting train epoch 23 / 50
loss: 0.09593227505683899
loss: 0.11799149960279465
loss: 0.24939075112342834
loss: 0.14481067657470703
loss: 0.1451997607946396
loss: 0.1398112028837204
loss: 0.17592105269432068
loss: 0.14982116222381592
loss: 0.17222754657268524
loss: 0.16206718981266022
loss: 0.10449934750795364
loss: 0.13808268308639526
loss: 0.15739357471466064
loss: 0.22855916619300842
loss: 0.1430702656507492
loss: 0.12226644903421402
loss: 0.11539486795663834
loss: 0.11105777323246002
loss: 0.12416090816259384
epoch loss: 0.14724516594096235
val_error: 0.15143783390522003
optimizer set.
Starting train epoch 24 / 50
loss: 0.11506533622741699
loss: 0.14810851216316223
loss: 0.1549486219882965
loss: 0.1431601643562317
loss: 0.1609087884426117
loss: 0.15463823080062866
loss: 0.23032012581825256
loss: 0.10890064388513565
loss: 0.14180317521095276
loss: 0.10831223428249359
loss: 0.1241752952337265
loss: 0.21660515666007996
loss: 0.1502760499715805
loss: 0.1556807905435562
loss: 0.13729973137378693
loss: 0.19336365163326263
loss: 0.1205771192908287
loss: 0.139884814620018
loss: 0.1283704936504364
epoch loss: 0.14907362821855044
val_error: 0.14427460730075836
optimizer set.
Starting train epoch 25 / 50
loss: 0.12260235846042633
loss: 0.09009720385074615
loss: 0.12591664493083954
loss: 0.1152888685464859
loss: 0.14288565516471863
loss: 0.09331004321575165
loss: 0.1099081039428711
loss: 0.10994286090135574
loss: 0.162061870098114
loss: 0.09986638277769089
loss: 0.13384296000003815
loss: 0.21108096837997437
loss: 0.1824689358472824
loss: 0.16021674871444702
loss: 0.14425645768642426
loss: 0.11214601248502731
loss: 0.1531156450510025
loss: 0.17109186947345734
loss: 0.21688707172870636
epoch loss: 0.1398414032239663
val_error: 0.16063886880874634
optimizer set.
Starting train epoch 26 / 50
loss: 0.15098275244235992
loss: 0.16070584952831268
loss: 0.1667766273021698
loss: 0.1397630274295807
loss: 0.14055991172790527
loss: 0.10428699105978012
loss: 0.13164262473583221
loss: 0.09571904689073563
loss: 0.22136752307415009
loss: 0.09711246937513351
loss: 0.11355625838041306
loss: 0.11047674715518951
loss: 0.11055680364370346
loss: 0.1665823757648468
loss: 0.14696644246578217
loss: 0.17076420783996582
loss: 0.14179646968841553
loss: 0.12575820088386536
loss: 0.13672702014446259
epoch loss: 0.1385316499754002
val_error: 0.1652550846338272
optimizer set.
Starting train epoch 27 / 50
loss: 0.15174579620361328
loss: 0.12489495426416397
loss: 0.1353587508201599
loss: 0.14687930047512054
loss: 0.25873345136642456
loss: 0.14844845235347748
loss: 0.19373944401741028
loss: 0.11656764894723892
loss: 0.14224973320960999
loss: 0.09047845005989075
loss: 0.19539304077625275
loss: 0.09029170870780945
loss: 0.19432149827480316
loss: 0.14610107243061066
loss: 0.08308117091655731
loss: 0.12924057245254517
loss: 0.16350284218788147
loss: 0.17719033360481262
loss: 0.11048069596290588
epoch loss: 0.14729994300164675
val_error: 0.14227764308452606
optimizer set.
Starting train epoch 28 / 50
loss: 0.1099686473608017
loss: 0.13081884384155273
loss: 0.12957939505577087
loss: 0.09736371040344238
loss: 0.11345358937978745
loss: 0.1385568380355835
loss: 0.14686515927314758
loss: 0.12065216153860092
loss: 0.16023673117160797
loss: 0.1427079737186432
loss: 0.16841353476047516
loss: 0.11690081655979156
loss: 0.1430376023054123
loss: 0.16878680884838104
loss: 0.0818176120519638
loss: 0.1009066104888916
loss: 0.13570891320705414
loss: 0.13082635402679443
loss: 0.10338345170021057
epoch loss: 0.12842025019620595
val_error: 0.13959191739559174
optimizer set.
Starting train epoch 29 / 50
loss: 0.12064500153064728
loss: 0.1217818483710289
loss: 0.11582545191049576
loss: 0.09395211189985275
loss: 0.12201936542987823
loss: 0.15590134263038635
loss: 0.19346843659877777
loss: 0.07978060841560364
loss: 0.1033783107995987
loss: 0.09383591264486313
loss: 0.13794328272342682
loss: 0.13837431371212006
loss: 0.14000731706619263
loss: 0.18730179965496063
loss: 0.20718614757061005
loss: 0.080104760825634
loss: 0.12065187841653824
loss: 0.13336493074893951
loss: 0.0775100514292717
epoch loss: 0.12752804591467506
val_error: 0.1436002552509308
optimizer set.
Starting train epoch 30 / 50
loss: 0.12263112515211105
loss: 0.21922236680984497
loss: 0.08050571382045746
loss: 0.13711386919021606
loss: 0.15952517092227936
loss: 0.1274901181459427
loss: 0.07750412821769714
loss: 0.17144186794757843
loss: 0.195292666554451
loss: 0.13159175217151642
loss: 0.17238633334636688
loss: 0.1519971489906311
loss: 0.16211935877799988
loss: 0.13189370930194855
loss: 0.11085837334394455
loss: 0.15557067096233368
loss: 0.11080645024776459
loss: 0.17984887957572937
loss: 0.1838286817073822
epoch loss: 0.14640149395716817
val_error: 0.13906294107437134
optimizer set.
Starting train epoch 31 / 50
loss: 0.11954016238451004
loss: 0.10231579095125198
loss: 0.1327134221792221
loss: 0.15357975661754608
loss: 0.08454584330320358
loss: 0.15291807055473328
loss: 0.19636428356170654
loss: 0.11167717725038528
loss: 0.13402383029460907
loss: 0.11614996939897537
loss: 0.1030891165137291
loss: 0.2004958987236023
loss: 0.11164765805006027
loss: 0.188319593667984
loss: 0.12403927743434906
loss: 0.14464262127876282
loss: 0.17872607707977295
loss: 0.11511538922786713
loss: 0.07651493698358536
epoch loss: 0.13402204607662402
val_error: 0.1352566033601761
optimizer set.
Starting train epoch 32 / 50
loss: 0.1482386440038681
loss: 0.15408411622047424
loss: 0.10433053970336914
loss: 0.11444278061389923
loss: 0.20530693233013153
loss: 0.18064627051353455
loss: 0.10468408465385437
loss: 0.11520963907241821
loss: 0.16999024152755737
loss: 0.14852941036224365
loss: 0.12442652136087418
loss: 0.08977853506803513
loss: 0.0797041654586792
loss: 0.1443718522787094
loss: 0.19376657903194427
loss: 0.13641667366027832
loss: 0.12584702670574188
loss: 0.11507432907819748
loss: 0.11099273711442947
epoch loss: 0.13504426730306526
val_error: 0.14467404782772064
optimizer set.
Starting train epoch 33 / 50
loss: 0.11279551684856415
loss: 0.12008505314588547
loss: 0.17931537330150604
loss: 0.1328900158405304
loss: 0.13928687572479248
loss: 0.14777711033821106
loss: 0.21470342576503754
loss: 0.1962975114583969
loss: 0.14866800606250763
loss: 0.14889439940452576
loss: 0.10444731265306473
loss: 0.12478144466876984
loss: 0.1313231736421585
loss: 0.23411042988300323
loss: 0.13167382776737213
loss: 0.10928048193454742
loss: 0.13649360835552216
loss: 0.17169643938541412
loss: 0.12432843446731567
epoch loss: 0.14783412845511185
val_error: 0.14180031418800354
optimizer set.
Starting train epoch 34 / 50
loss: 0.12145566195249557
loss: 0.07335375994443893
loss: 0.16777431964874268
loss: 0.15014897286891937
loss: 0.15313929319381714
loss: 0.12396454811096191
loss: 0.16454245150089264
loss: 0.1940394937992096
loss: 0.11093802005052567
loss: 0.10317223519086838
loss: 0.1485186219215393
loss: 0.16751636564731598
loss: 0.07709463685750961
loss: 0.17950840294361115
loss: 0.11719075590372086
loss: 0.16194204986095428
loss: 0.11758971214294434
loss: 0.13743025064468384
loss: 0.18716199696063995
epoch loss: 0.139814818375989
val_error: 0.14313122630119324
optimizer set.
Starting train epoch 35 / 50
loss: 0.13025924563407898
loss: 0.09474851191043854
loss: 0.11344527453184128
loss: 0.3222353756427765
loss: 0.09895345568656921
loss: 0.13541331887245178
loss: 0.12695707380771637
loss: 0.11257421225309372
loss: 0.15092045068740845
loss: 0.07222840934991837
loss: 0.11588366329669952
loss: 0.12604808807373047
loss: 0.1322547346353531
loss: 0.07164228707551956
loss: 0.13696911931037903
loss: 0.12091188877820969
loss: 0.11634530872106552
loss: 0.23047210276126862
loss: 0.14467014372348785
epoch loss: 0.13436487709221087
val_error: 0.13307829201221466
optimizer set.
Starting train epoch 36 / 50
loss: 0.14424701035022736
loss: 0.16463753581047058
loss: 0.08157151192426682
loss: 0.13049660623073578
loss: 0.12835684418678284
loss: 0.16996951401233673
loss: 0.12166721373796463
loss: 0.10097745805978775
loss: 0.10574439913034439
loss: 0.12709364295005798
loss: 0.08392561972141266
loss: 0.08740054070949554
loss: 0.1563442200422287
loss: 0.11688303202390671
loss: 0.0762830376625061
loss: 0.1318231225013733
loss: 0.10586593300104141
loss: 0.09649214893579483
loss: 0.12079215794801712
epoch loss: 0.11845113415467112
val_error: 0.14446628093719482
optimizer set.
Starting train epoch 37 / 50
loss: 0.14032500982284546
loss: 0.16486531496047974
loss: 0.13340239226818085
loss: 0.133549764752388
loss: 0.20621567964553833
loss: 0.1135413646697998
loss: 0.08964081853628159
loss: 0.09873677790164948
loss: 0.07600025087594986
loss: 0.10328588634729385
loss: 0.14334331452846527
loss: 0.1828836351633072
loss: 0.16207095980644226
loss: 0.0993124321103096
loss: 0.1462719887495041
loss: 0.0944499522447586
loss: 0.16694606840610504
loss: 0.20904771983623505
loss: 0.13564108312129974
epoch loss: 0.13681739019720177
val_error: 0.1471133679151535
optimizer set.
Starting train epoch 38 / 50
loss: 0.09216824173927307
loss: 0.1755465567111969
loss: 0.13064217567443848
loss: 0.17602503299713135
loss: 0.16621345281600952
loss: 0.12033316493034363
loss: 0.19580286741256714
loss: 0.1880042552947998
loss: 0.09916138648986816
loss: 0.11924625188112259
loss: 0.11335480958223343
loss: 0.10421662777662277
loss: 0.11707907170057297
loss: 0.12232492119073868
loss: 0.1302131712436676
loss: 0.14180828630924225
loss: 0.15498696267604828
loss: 0.15570548176765442
loss: 0.11090664565563202
epoch loss: 0.13756522967627174
val_error: 0.13310043513774872
optimizer set.
Starting train epoch 39 / 50
loss: 0.10604570806026459
loss: 0.13820455968379974
loss: 0.08724323660135269
loss: 0.10346001386642456
loss: 0.13738664984703064
loss: 0.1355782449245453
loss: 0.15955351293087006
loss: 0.15306957066059113
loss: 0.16740691661834717
loss: 0.16948457062244415
loss: 0.1292545646429062
loss: 0.09244028478860855
loss: 0.11671680957078934
loss: 0.1583871990442276
loss: 0.16639892756938934
loss: 0.0830940380692482
loss: 0.10295799374580383
loss: 0.1360599547624588
loss: 0.18576884269714355
epoch loss: 0.1330795578266445
val_error: 0.1519680619239807
optimizer set.
Starting train epoch 40 / 50
loss: 0.1316526085138321
loss: 0.16672520339488983
loss: 0.15269775688648224
loss: 0.15028347074985504
loss: 0.17384441196918488
loss: 0.15494069457054138
loss: 0.09816146641969681
loss: 0.15332645177841187
loss: 0.19293422996997833
loss: 0.08296006172895432
loss: 0.1257324069738388
loss: 0.1517486274242401
loss: 0.10418622195720673
loss: 0.15422874689102173
loss: 0.15848366916179657
loss: 0.1171078011393547
loss: 0.12495194375514984
loss: 0.09050017595291138
loss: 0.10467112064361572
epoch loss: 0.13627037209899803
val_error: 0.13793036341667175
optimizer set.
Starting train epoch 41 / 50
loss: 0.11836472153663635
loss: 0.12928850948810577
loss: 0.10605604201555252
loss: 0.14468374848365784
loss: 0.06799273192882538
loss: 0.12727966904640198
loss: 0.12041731923818588
loss: 0.13171705603599548
loss: 0.20898695290088654
loss: 0.11054851859807968
loss: 0.12178376317024231
loss: 0.16206522285938263
loss: 0.19375678896903992
loss: 0.1248648539185524
loss: 0.22483548521995544
loss: 0.1010393425822258
loss: 0.12640587985515594
loss: 0.18098150193691254
loss: 0.12162565439939499
epoch loss: 0.13803651379911522
val_error: 0.148924320936203
optimizer set.
Starting train epoch 42 / 50
loss: 0.10948622226715088
loss: 0.10620780289173126
loss: 0.1102282926440239
loss: 0.12146300822496414
loss: 0.11079182475805283
loss: 0.120452880859375
loss: 0.23891790211200714
loss: 0.12653498351573944
loss: 0.11518427729606628
loss: 0.09902758151292801
loss: 0.13480542600154877
loss: 0.13872842490673065
loss: 0.16677449643611908
loss: 0.1298096477985382
loss: 0.1547468900680542
loss: 0.10097935795783997
loss: 0.08837906271219254
loss: 0.15585216879844666
loss: 0.2121119350194931
epoch loss: 0.1337095887253159
val_error: 0.15444090962409973
optimizer set.
Starting train epoch 43 / 50
loss: 0.10221196711063385
loss: 0.2078719139099121
loss: 0.1276489496231079
loss: 0.142473503947258
loss: 0.21485547721385956
loss: 0.15291476249694824
loss: 0.0889933779835701
loss: 0.08743450045585632
loss: 0.10456663370132446
loss: 0.0928773507475853
loss: 0.10770165920257568
loss: 0.08202944695949554
loss: 0.09284498542547226
loss: 0.122134730219841
loss: 0.1184072196483612
loss: 0.0978052169084549
loss: 0.1047210693359375
loss: 0.11489108949899673
loss: 0.0850304663181305
epoch loss: 0.11828496424775374
val_error: 0.13584280014038086
optimizer set.
Starting train epoch 44 / 50
loss: 0.10333680361509323
loss: 0.11975636333227158
loss: 0.23727157711982727
loss: 0.15386995673179626
loss: 0.07752762734889984
loss: 0.18894268572330475
loss: 0.11250718683004379
loss: 0.12361163645982742
loss: 0.10351558029651642
loss: 0.07204398512840271
loss: 0.16481837630271912
loss: 0.09045955538749695
loss: 0.12939120829105377
loss: 0.07317165285348892
loss: 0.11278756707906723
loss: 0.09607518464326859
loss: 0.1910596787929535
loss: 0.13249212503433228
loss: 0.1494394689798355
epoch loss: 0.12800411683948418
val_error: 0.13740891218185425
optimizer set.
Starting train epoch 45 / 50
loss: 0.10708251595497131
loss: 0.10181200504302979
loss: 0.1924285739660263
loss: 0.13626107573509216
loss: 0.10421285033226013
loss: 0.15424926578998566
loss: 0.11020451039075851
loss: 0.1222182959318161
loss: 0.08389245718717575
loss: 0.19560103118419647
loss: 0.09857163578271866
loss: 0.11987148225307465
loss: 0.08047505468130112
loss: 0.09952396899461746
loss: 0.15224850177764893
loss: 0.17155516147613525
loss: 0.1334044337272644
loss: 0.17088666558265686
loss: 0.07829045504331589
epoch loss: 0.12698894425442345
val_error: 0.14541922509670258
optimizer set.
Starting train epoch 46 / 50
loss: 0.13328883051872253
loss: 0.14337927103042603
loss: 0.130085751414299
loss: 0.26414746046066284
loss: 0.12220501154661179
loss: 0.2219945788383484
loss: 0.17435947060585022
loss: 0.14981919527053833
loss: 0.11792950332164764
loss: 0.16317908465862274
loss: 0.16201387345790863
loss: 0.1293409913778305
loss: 0.09705757349729538
loss: 0.16984738409519196
loss: 0.1292293667793274
loss: 0.09311320632696152
loss: 0.12100177258253098
loss: 0.14187085628509521
loss: 0.11117170751094818
epoch loss: 0.14605446787256943
val_error: 0.133773535490036
optimizer set.
Starting train epoch 47 / 50
loss: 0.14914147555828094
loss: 0.14946886897087097
loss: 0.0892951712012291
loss: 0.10560675710439682
loss: 0.16382306814193726
loss: 0.13061478734016418
loss: 0.08820650726556778
loss: 0.08350863307714462
loss: 0.13341212272644043
loss: 0.14850153028964996
loss: 0.16640986502170563
loss: 0.09155642986297607
loss: 0.13877208530902863
loss: 0.146979421377182
loss: 0.16399425268173218
loss: 0.10046011954545975
loss: 0.12573373317718506
loss: 0.13675029575824738
loss: 0.1190478652715683
epoch loss: 0.12796226261477722
val_error: 0.13857242465019226
optimizer set.
Starting train epoch 48 / 50
loss: 0.0876721739768982
loss: 0.10873407125473022
loss: 0.12935833632946014
loss: 0.12427301704883575
loss: 0.10338272899389267
loss: 0.17026424407958984
loss: 0.12784326076507568
loss: 0.15694044530391693
loss: 0.08374316245317459
loss: 0.11823873966932297
loss: 0.0856408104300499
loss: 0.12495646625757217
loss: 0.11385135352611542
loss: 0.10318658500909805
loss: 0.0999116525053978
loss: 0.10130596160888672
loss: 0.13402792811393738
loss: 0.12695328891277313
loss: 0.12512747943401337
epoch loss: 0.11712693187751268
val_error: 0.14037172496318817
optimizer set.
Starting train epoch 49 / 50
loss: 0.14871397614479065
loss: 0.19190311431884766
loss: 0.1268007904291153
loss: 0.10670101642608643
loss: 0.19006642699241638
loss: 0.08171965181827545
loss: 0.1098463386297226
loss: 0.1472242921590805
loss: 0.16007260978221893
loss: 0.10483857989311218
loss: 0.17315702140331268
loss: 0.10200361162424088
loss: 0.14486680924892426
loss: 0.07275822758674622
loss: 0.10236667841672897
loss: 0.21804440021514893
loss: 0.20413601398468018
loss: 0.07115010172128677
loss: 0.10956422239542007
epoch loss: 0.13504915174685025
val_error: 0.1406441628932953
optimizer set.
Starting train epoch 50 / 50
loss: 0.09734231978654861
loss: 0.11569396406412125
loss: 0.13680030405521393
loss: 0.13141824305057526
loss: 0.1553618609905243
loss: 0.17634546756744385
loss: 0.1037905141711235
loss: 0.12752458453178406
loss: 0.07555448263883591
loss: 0.16383932530879974
loss: 0.1479610949754715
loss: 0.1337227076292038
loss: 0.09652068465948105
loss: 0.0815802663564682
loss: 0.1740923672914505
loss: 0.08458784967660904
loss: 0.11029481887817383
loss: 0.11212428659200668
loss: 0.13934612274169922
epoch loss: 0.12441585605081759
val_error: 0.12923875451087952
